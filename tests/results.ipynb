{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Polymarket Election Prediction Analysis\n",
    "====================================================\n",
    "\n",
    "This notebook integrates results from:\n",
    "- Feature importance analysis\n",
    "- Feature relationship analysis\n",
    "- Prediction error analysis\n",
    "- Actionable insights development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML/.venv/lib/python3.13/site-packages/matplotlib/style/core.py:129\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     style = \u001b[43m_rc_params_in_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML/.venv/lib/python3.13/site-packages/matplotlib/__init__.py:903\u001b[39m, in \u001b[36m_rc_params_in_file\u001b[39m\u001b[34m(fname, transform, fail_on_error)\u001b[39m\n\u001b[32m    902\u001b[39m rc_temp = {}\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_file_or_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:141\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML/.venv/lib/python3.13/site-packages/matplotlib/__init__.py:880\u001b[39m, in \u001b[36m_open_file_or_url\u001b[39m\u001b[34m(fname)\u001b[39m\n\u001b[32m    879\u001b[39m fname = os.path.expanduser(fname)\n\u001b[32m--> \u001b[39m\u001b[32m880\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'whitegrid'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Set plotting style\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwhitegrid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m sns.set_context(\u001b[33m\"\u001b[39m\u001b[33mpaper\u001b[39m\u001b[33m\"\u001b[39m, font_scale=\u001b[32m1.2\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create output directory for combined results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML/.venv/lib/python3.13/site-packages/matplotlib/style/core.py:131\u001b[39m, in \u001b[36muse\u001b[39m\u001b[34m(style)\u001b[39m\n\u001b[32m    129\u001b[39m         style = _rc_params_in_file(style)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstyle\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m is not a valid package style, path of style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile, URL of style file, or library style name (library \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstyles are listed in `style.available`)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    135\u001b[39m filtered = {}\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m style:  \u001b[38;5;66;03m# don't trigger RcParams.__getitem__('backend')\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: 'whitegrid' is not a valid package style, path of style file, URL of style file, or library style name (library styles are listed in `style.available`)"
     ]
    }
   ],
   "source": [
    "# Set plotting style - use a current style\n",
    "plt.style.use('default')  # Use default style\n",
    "sns.set_theme(style=\"whitegrid\")  # Use whitegrid from current seaborn\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# Create output directory for combined results\n",
    "output_dir = \"combined_analysis\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load core datasets\n",
    "df = pd.read_csv(\"modified_analysis/cleaned_election_data.csv\")\n",
    "feature_importance = pd.read_csv(\"feature_importance_results/consensus_feature_ranking.csv\")\n",
    "\n",
    "# Try to load error patterns, but handle case if file doesn't exist\n",
    "try:\n",
    "    error_patterns = pd.read_csv(\"prediction_error_analysis/error_patterns_by_feature_bin.csv\")\n",
    "except FileNotFoundError:\n",
    "    error_patterns = pd.DataFrame()\n",
    "    print(\"Error patterns file not found. Will skip that analysis.\")\n",
    "\n",
    "# Try to load thresholds, but handle case if file doesn't exist\n",
    "try:\n",
    "    thresholds = pd.read_csv(\"actionable_insights/market_quality_thresholds.csv\")\n",
    "except FileNotFoundError:\n",
    "    thresholds = pd.DataFrame()\n",
    "    print(\"Thresholds file not found. Will use correlation data instead.\")\n",
    "    # Create a simple version based on correlations if needed\n",
    "    if 'feature' in feature_importance.columns:\n",
    "        thresholds = pd.DataFrame({\n",
    "            'feature': feature_importance['feature'].head(10),\n",
    "            'direction': [\"Higher is better\"] * 10,  # Will be fixed later\n",
    "            'suggested_threshold': [0] * 10  # Will be calculated later\n",
    "        })\n",
    "\n",
    "# Define top features based on consensus ranking or fall back to important columns\n",
    "top_features = []\n",
    "if 'feature' in feature_importance.columns:\n",
    "    top_features = feature_importance['feature'].head(10).tolist()\n",
    "else:\n",
    "    print(\"Feature importance file doesn't have expected format.\")\n",
    "    # Fall back to common important features from your previous results\n",
    "    top_features = [\n",
    "        'price_range', 'unique_traders_count', 'price_fluctuations', \n",
    "        'volumeNum', 'final_week_momentum', 'buy_sell_ratio',\n",
    "        'event_commentCount', 'price_volatility', 'volume_acceleration', \n",
    "        'trader_concentration'\n",
    "    ]\n",
    "    # Filter to only include columns that exist in the dataset\n",
    "    top_features = [f for f in top_features if f in df.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display key metrics\n",
    "display(Markdown(\"### Model Performance\"))\n",
    "model_performance = pd.read_csv(\"feature_importance_results/model_performance_comparison.csv\")\n",
    "display(model_performance)\n",
    "\n",
    "# Create executive summary table\n",
    "display(Markdown(\"### Top Predictive Features\"))\n",
    "top_features_summary = feature_importance.head(10).copy()\n",
    "\n",
    "# Enrich with directional relationship to accuracy\n",
    "for idx, row in top_features_summary.iterrows():\n",
    "    feature = row['feature']\n",
    "    corr = df[['brier_score', feature]].corr().iloc[0, 1]\n",
    "    relationship = \"Higher values → worse predictions\" if corr > 0 else \"Lower values → worse predictions\"\n",
    "    top_features_summary.loc[idx, 'relationship_to_accuracy'] = relationship\n",
    "    top_features_summary.loc[idx, 'correlation_with_brier'] = corr\n",
    "\n",
    "display(top_features_summary[['feature', 'importance_score', 'relationship_to_accuracy', 'correlation_with_brier']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Integrated Feature Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for top features + brier score\n",
    "correlation_df = df[top_features + ['brier_score']].corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_df, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(correlation_df, mask=mask, cmap=cmap, vmax=.5, vmin=-.5, \n",
    "            square=True, linewidths=.5, annot=True, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/integrated_correlation_matrix.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature-Error Relationship Analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load error data\n",
    "largest_errors = pd.read_csv(\"prediction_error_analysis/largest_error_markets.csv\")\n",
    "\n",
    "display(Markdown(\"### Markets with Largest Prediction Errors\"))\n",
    "display(largest_errors[['question', 'actual_brier', 'predicted_brier', 'error']].head())\n",
    "\n",
    "# Integrate feature values with error analysis\n",
    "# Load the test data with feature values\n",
    "X_test_orig = pd.read_csv(\"modified_analysis/X_test_original.csv\")\n",
    "\n",
    "# Create integrated error analysis that combines error magnitude with feature values\n",
    "display(Markdown(\"### Error Patterns by Feature Values\"))\n",
    "\n",
    "# Select 2-3 most important features for detailed error analysis\n",
    "key_features = top_features[:3]\n",
    "\n",
    "fig, axes = plt.subplots(len(key_features), 1, figsize=(10, 4*len(key_features)))\n",
    "\n",
    "for i, feature in enumerate(key_features):\n",
    "    if feature in X_test_orig.columns:\n",
    "        # Load error data from prediction error analysis\n",
    "        # In a real notebook, you might need to recreate this from your model results\n",
    "        error_feature_df = pd.read_csv(f\"prediction_error_analysis/error_by_{feature}.csv\", \n",
    "                                      error_bad_lines=False) if os.path.exists(f\"prediction_error_analysis/error_by_{feature}.csv\") else None\n",
    "        \n",
    "        if error_feature_df is not None:\n",
    "            sns.scatterplot(x=feature, y='abs_error', data=error_feature_df, ax=axes[i])\n",
    "            sns.regplot(x=feature, y='abs_error', data=error_feature_df, \n",
    "                      scatter=False, line_kws={\"color\": \"red\"}, ax=axes[i])\n",
    "            axes[i].set_title(f'Error Magnitude by {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/integrated_error_analysis.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Actionable Insights Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table showing the thresholds for good prediction quality\n",
    "display(Markdown(\"### Market Quality Indicators\"))\n",
    "display(thresholds)\n",
    "\n",
    "# Generate a scoring example\n",
    "display(Markdown(\"### Practical Application Example\"))\n",
    "\n",
    "# Calculate a quality score for each market\n",
    "# Create scoring function based on thresholds\n",
    "def calculate_quality_score(market_data, threshold_data):\n",
    "    score = 0\n",
    "    reasons = []\n",
    "    \n",
    "    for _, row in threshold_data.iterrows():\n",
    "        feature = row['feature']\n",
    "        threshold = row['suggested_threshold']\n",
    "        direction = row['direction']\n",
    "        \n",
    "        if feature in market_data:\n",
    "            value = market_data[feature]\n",
    "            \n",
    "            if direction == \"Lower is better\" and value <= threshold:\n",
    "                score += 1\n",
    "                reasons.append(f\"{feature}: {value:.4f} ≤ {threshold:.4f} ✓\")\n",
    "            elif direction == \"Higher is better\" and value >= threshold:\n",
    "                score += 1\n",
    "                reasons.append(f\"{feature}: {value:.4f} ≥ {threshold:.4f} ✓\")\n",
    "            else:\n",
    "                if direction == \"Lower is better\":\n",
    "                    reasons.append(f\"{feature}: {value:.4f} > {threshold:.4f} ✗\")\n",
    "                else:\n",
    "                    reasons.append(f\"{feature}: {value:.4f} < {threshold:.4f} ✗\")\n",
    "    \n",
    "    return score, reasons\n",
    "\n",
    "# Select a few example markets with different Brier scores\n",
    "example_markets = df.sort_values('brier_score').iloc[[0, len(df)//4, len(df)//2, 3*len(df)//4, -1]].copy()\n",
    "\n",
    "# Calculate quality score for each example\n",
    "for idx, market in example_markets.iterrows():\n",
    "    score, reasons = calculate_quality_score(market, thresholds)\n",
    "    example_markets.loc[idx, 'quality_score'] = score\n",
    "    example_markets.loc[idx, 'quality_assessment'] = '; '.join(reasons[:3]) + \"...\" if len(reasons) > 3 else '; '.join(reasons)\n",
    "\n",
    "display(example_markets[['question', 'brier_score', 'quality_score', 'quality_assessment']])\n",
    "\n",
    "# Save the consolidated analysis\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
